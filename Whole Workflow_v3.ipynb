{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5d71fbd",
   "metadata": {},
   "source": [
    "# TODOs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5445581f",
   "metadata": {},
   "source": [
    "1. Data Generation:\n",
    "    - numerical data generation - improvements in distribution, - ***DONE*** \n",
    "    - business rules adjustments (only after numerical data generation is fixed)\n",
    "    - check the distribution of each numerical feature of the merged data - ***DONE***\n",
    "    - categorical data - add a check (with Kolmogorov Smirnov or another one) that tells you if the distribution of the synthetic data is ok - ***DONE***\n",
    "<br>\n",
    "<br>\n",
    "2. Feature Engineering:\n",
    "    - Generate new features (**custom made**, statistical) - ***Girls***\n",
    "    - Balance data \n",
    "        - research other methods beside SMOTE; **Multiclass problems handling - should we resample for each target class individually or not. Describe all possible prediction scenarious** - ***ALL***\n",
    "<br>\n",
    "<br>\n",
    "3. Feature Selection \n",
    "    - research methods for numerical and categorical feature selections\n",
    "<br>\n",
    "<br>\n",
    "4. Modeling:\n",
    "    - try different models - with at least 5k examples!!! \n",
    "        - black box and explainable ones\n",
    "    - visualizations - compare performances\n",
    "    - try to explain the black box models (OPTIONAL)\n",
    "    - hyperparam optimization (OPTIONAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553b783b",
   "metadata": {},
   "source": [
    "# Inputs and tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd05fea7",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9844e263",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T22:59:52.776236Z",
     "start_time": "2023-07-19T22:59:48.520347Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,roc_curve, roc_auc_score, precision_score, recall_score, precision_recall_curve\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "from fitter import Fitter, get_common_distributions, get_distributions\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Increase the maximum number of rows and columns to be displayed\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e4965",
   "metadata": {},
   "source": [
    "## Categorical data distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e973056b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T22:59:52.824086Z",
     "start_time": "2023-07-19T22:59:52.781238Z"
    }
   },
   "outputs": [],
   "source": [
    "dists = {\n",
    "    'sex':{'labels':['M', 'F'], 'values':[0.4854368932,0.5145631068]},\n",
    "    'lv_educ':{'labels':['Incomplete', 'Primary', 'Basic', 'Secondary', 'Higher'], 'values':[0.0595,0.07788016474,0.2309254283,0.4359496722,0.1957067711]},\n",
    "    'empl_stat':{'labels':['Employers', 'Self-employed', 'Employed in private sector', 'Employed in public sector', 'Unpaid family workers'], 'values':[0.03631598652,0.07272557095,0.6708785723,0.2126544365,0.00742543367]},\n",
    "    'marit_stat':{'labels':['Single', 'Married', 'Divorced', 'Widowed'], 'values':[0.397,0.443,0.058,0.102]},\n",
    "    'house_memb':{'labels':['1', '2', '3', '4', '5', '6', '7+'], 'values':[0.1805,0.3778,0.2387,0.1157,0.0525,0.0238,0.011]},\n",
    "    'chil_u_18_y':{'labels':['No children under 18', 'One child under 18', 'Two children under 18', 'Three children under 18', 'Four children under 18', 'Five children under 18', 'Six or more children under 18'], 'values':[0.422602157,0.36552047,0.183222339,0.020674764,0.004993779,0.001875149,0.001111341]},\n",
    "    'nation':{'labels':['Bulgaria', 'EU', 'Other'], 'values':[0.9950198043,0.001146570676,0.003833625045]},\n",
    "    'religion':{'labels':['Protestant', 'Catholic', 'Orthodox', 'Muslim', 'Other', 'No religion', 'I do not identify myself'], 'values':[0.011,0.008,0.76,0.1,0.002,0.047,0.072]},\n",
    "    'soc_econ_stat':{'labels':['Economically active', 'Economically inactive'], 'values':[0.6151643031,0.3848356969]},\n",
    "    'prof_ind':{'labels':['Agriculture, forestry and fisheries', 'Mining and processing industry', 'Utilities (electricity distribution and water supply)', 'Construction', 'Trade, automobile and motorcycle repair', 'Transportation, warehousing and mail', 'Hospitality and restaurant services', 'Creation and distribution of information and creative products, Telecommunications', 'Financial and administrative activities', 'Public administration', 'Education and research', 'Human health and social work', 'Other activities'], 'values':[0.03090815115,0.2353,0.029,0.05523651408,0.1645618594,0.06439111505,0.05161626582,0.03936261795,0.07356911161,0.04836124844,0.104946474,0.06006423384,0.04269692032]},\n",
    "    'prof_stat':{'labels':['Management contract', 'Employment contract', 'Civil contract', 'Self-employed', 'Unemployed', 'Pensioner'], 'values':[0.01783393631,0.4732428049,0.02497602302,0.0385148509,0.167699009,0.277733376]},\n",
    "    'count_house':{'labels':['0', '1', '2+'], 'values':[0.37,0.6,0.03]},\n",
    "    'own_field':{'labels':['YES', 'NO'], 'values':[0.2621335023,0.737866497676384]},\n",
    "    'num_car_house':{'labels':['0', '1', '2', '3+'], 'values':[0.5714285714,0.36,0.06428571429,0.004285714286]},\n",
    "    'own_rent_house':{'labels':['my own', 'rented'], 'values':[0.843,0.157]},\n",
    "    'edu':{'labels':['Educational Sciences', 'Humanities', 'Social, Economic and Legal Sciences', 'Natural Sciences, Mathematics and Informatics', 'Technical Sciences', 'Agricultural Sciences and Veterinary Medicine', 'Health and Sports', 'Arts', 'Security and Defense'], 'values':[0.07591254907,0.0461889827,0.5266633332,0.04571641724,0.1533297557,0.01776640163,0.0930038303,0.02247374859,0.01891291637]},\n",
    "    'temp':{'labels':['Choleric', 'Phlegmatic', 'Sanguine', 'Melancholic'], 'values':[0.38,0.11,0.23,0.28]},\n",
    "    'invest_exp':{'labels':['0', '1-5', '6-10', '11-15', '16-25'], 'values':[0.7,0.2,0.06,0.03,0.01]},\n",
    "    'shares':{'labels':['YES', 'NO'], 'values':[0.003394353314,0.9966056467]},\n",
    "    'corp_oblig':{'labels':['YES', 'NO'], 'values':[0.0003792213936,0.9996207786]},\n",
    "    'oth':{'labels':['YES', 'NO'], 'values':[0.000592597502012084,0.999407402497988]},\n",
    "    'inv_fund':{'labels':['YES', 'NO'], 'values':[0.06491199709,0.9350880029]},\n",
    "    'cash':{'labels':['YES', 'NO'], 'values':[0.04105169923,0.9589483008]},\n",
    "    'crypto':{'labels':['YES', 'NO'], 'values':[0.003284135938,0.9967158641]},\n",
    "    'gov_bond':{'labels':['YES', 'NO'], 'values':[0.06835666691,0.9316433331]},\n",
    "    'deposits':{'labels':['YES', 'NO'], 'values':[0.8180293286,0.1819706714]},\n",
    "    'banking':{'labels':['Online', 'Offline'], 'values':[0.09,0.91]},\n",
    "    'bk_oprat':{'labels':['Up to 7', 'From 8 to 10', 'From 11 to 13', 'From 14 to 18', 'From 19 to more'], 'values':[0.0084,0.2424,0.4729,0.2615,0.0148]},\n",
    "    'bk_dc':{'labels':['Under one', 'One', 'Two', 'Three'], 'values':[0.01,0.57,0.38,0.04]},\n",
    "    'bk_cc':{'labels':['YES', 'NO'], 'values':[0.17,0.83]},\n",
    "    'bk_acc':{'labels':['YES', 'NO'], 'values':[0.8634087377,0.1365912623]},\n",
    "    'ins_prop':{'labels':['YES', 'NO'], 'values':[0.05,0.95]},\n",
    "    'ins_life':{'labels':['YES', 'NO'], 'values':[0.09,0.91]},\n",
    "    'ins_casco':{'labels':['YES', 'NO'], 'values':[0.03,0.97]},\n",
    "    'health_ins':{'labels':['YES', 'NO'], 'values':[0.02,0.98]},\n",
    "    'overdraft':{'labels':['YES', 'NO'], 'values':[0.19,0.81]},\n",
    "    'cons_cred':{'labels':['YES', 'NO'], 'values':[0.26,0.74]},\n",
    "    'mortgage':{'labels':['YES', 'NO'], 'values':[0.02,0.98]},\n",
    "    'car_leas':{'labels':['YES', 'NO'], 'values':[0.2,0.8]},\n",
    "    'pens_ins':{'labels':['YES', 'NO'], 'values':[0.11,0.89]},\n",
    "    'overdraft_app':{'labels':['YES', 'NO'], 'values':[0.2439,0.7561]},\n",
    "    'cons_cred_app':{'labels':['YES', 'NO'], 'values':[0.305299502487562,0.694700497512438]},\n",
    "    'mortgage_app':{'labels':['YES', 'NO'], 'values':[0.03,0.97]},\n",
    "    'bk_cc_app':{'labels':['YES', 'NO'], 'values':[0.21,0.79]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637a4dbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T22:59:52.871097Z",
     "start_time": "2023-07-19T22:59:52.827566Z"
    }
   },
   "outputs": [],
   "source": [
    "len(dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01e3c2f",
   "metadata": {},
   "source": [
    "## Correlation of Numerical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f1a5da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T22:59:52.902251Z",
     "start_time": "2023-07-19T22:59:52.877187Z"
    }
   },
   "outputs": [],
   "source": [
    "corr = {\n",
    "    'features': ['age', 'ind_risk', 'income', 'pers_exp', 'house_exp', 'taxes', 'transp_telecom', 'hobby'],\n",
    "    'age': [1, -0.00665947056405372, 0.00291644965339247, 0.0107779942638097, 0.00698674581731255, 0.00729153655132963, 0.0099866509330216, 0.00931630696561133],\n",
    "    'ind_risk': [-0.00665947056405372, 1, 0.0039918072709289, 0.00806259039194059, 0.00457023635440603, 0.0061985340641631, 0.00768699810849585, -0.00332322616613201],\n",
    "    'income': [0.00291644965339247, 0.0039918072709289, 1, 0.560949334881676, 0.58892666343229, 0.581907424628933, 0.562946509689962, 0.352350802339294],\n",
    "    'pers_exp': [0.0107779942638097, 0.00806259039194059, 0.560949334881676, 1, 0.928449923861951, 0.929598634668897, 0.934775947642248, 0.714298364869941],\n",
    "    'house_exp': [0.00698674581731255, 0.00457023635440603, 0.58892666343229, 0.928449923861951, 1, 0.93031279279417, 0.927846735467478, 0.679286362990223],\n",
    "    'taxes': [0.00729153655132963, 0.0061985340641631, 0.581907424628933, 0.929598634668897, 0.93031279279417, 1, 0.92920510128812, 0.689442053350162],\n",
    "    'transp_telecom': [0.0099866509330216, 0.00768699810849585, 0.562946509689962, 0.934775947642248, 0.927846735467478, 0.92920510128812, 1, 0.714114127908189],\n",
    "    'hobby': [0.00931630696561133, -0.00332322616613201, 0.352350802339294, 0.714298364869941, 0.679286362990223, 0.689442053350162, 0.714114127908189, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11400b94",
   "metadata": {},
   "source": [
    "## Extract distributions from dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c072733",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T22:59:52.918251Z",
     "start_time": "2023-07-19T22:59:52.906257Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_dists(x, dists):\n",
    "    '''\n",
    "    A function to extract distributions from the dictionary dists,where:\n",
    "    x is the name of the feature to extract in ''\n",
    "    dists is the dictionary with all distributions\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    column_names = dists[x]['labels']\n",
    "    values = [dists[x]['values']]\n",
    "    pd_df = pd.DataFrame(data=values, columns=column_names)\n",
    "    pd_df.index = pd.Index([x])\n",
    "    return pd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e2cd86",
   "metadata": {},
   "source": [
    "## Convert the dictionary with correlation matrix to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2d6b3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T22:59:52.934253Z",
     "start_time": "2023-07-19T22:59:52.922252Z"
    }
   },
   "outputs": [],
   "source": [
    "def corr2df(corr):\n",
    "    '''\n",
    "    A function to create correlation dataframe from dictionary corr, where\n",
    "    corr is the dictionary with the correlation matrix\n",
    "    '''\n",
    "    import pandas as df\n",
    "    corr_df = pd.DataFrame(corr)\n",
    "    corr_df.set_index('features', inplace=True)\n",
    "    corr_df.index.name=None\n",
    "    return corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5906342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e2a38d8",
   "metadata": {},
   "source": [
    "# Data Generation (Data synthesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b5e8bf",
   "metadata": {},
   "source": [
    "## Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645787fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T22:59:53.767244Z",
     "start_time": "2023-07-19T22:59:52.938928Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Given dictionary\n",
    "dists = {\n",
    "    'sex':{'labels':['M', 'F'], 'values':[0.4854368932,0.5145631068]},\n",
    "    'lv_educ':{'labels':['Incomplete', 'Primary', 'Basic', 'Secondary', 'Higher'], 'values':[0.0595,0.07788016474,0.2309254283,0.4359496722,0.1957067711]},\n",
    "    'empl_stat':{'labels':['Employers', 'Self-employed', 'Employed in private sector', 'Employed in public sector', 'Unpaid family workers'], 'values':[0.03631598652,0.07272557095,0.6708785723,0.2126544365,0.00742543367]},\n",
    "    'marit_stat':{'labels':['Single', 'Married', 'Divorced', 'Widowed'], 'values':[0.397,0.443,0.058,0.102]},\n",
    "    'house_memb':{'labels':['1', '2', '3', '4', '5', '6', '7+'], 'values':[0.1805,0.3778,0.2387,0.1157,0.0525,0.0238,0.011]},\n",
    "    'chil_u_18_y':{'labels':['No children under 18', 'One child under 18', 'Two children under 18', 'Three children under 18', 'Four children under 18', 'Five children under 18', 'Six or more children under 18'], 'values':[0.422602157,0.36552047,0.183222339,0.020674764,0.004993779,0.001875149,0.001111341]},\n",
    "    'nation':{'labels':['Bulgaria', 'EU', 'Other'], 'values':[0.9950198043,0.001146570676,0.003833625045]},\n",
    "    'religion':{'labels':['Protestant', 'Catholic', 'Orthodox', 'Muslim', 'Other', 'No religion', 'I do not identify myself'], 'values':[0.011,0.008,0.76,0.1,0.002,0.047,0.072]},\n",
    "    'soc_econ_stat':{'labels':['Economically active', 'Economically inactive'], 'values':[0.6151643031,0.3848356969]},\n",
    "    'prof_ind':{'labels':['Agriculture, forestry and fisheries', 'Mining and processing industry', 'Utilities (electricity distribution and water supply)', 'Construction', 'Trade, automobile and motorcycle repair', 'Transportation, warehousing and mail', 'Hospitality and restaurant services', 'Creation and distribution of information and creative products, Telecommunications', 'Financial and administrative activities', 'Public administration', 'Education and research', 'Human health and social work', 'Other activities'], 'values':[0.03090815115,0.2353,0.029,0.05523651408,0.1645618594,0.06439111505,0.05161626582,0.03936261795,0.07356911161,0.04836124844,0.104946474,0.06006423384,0.04269692032]},\n",
    "    'prof_stat':{'labels':['Management contract', 'Employment contract', 'Civil contract', 'Self-employed', 'Unemployed', 'Pensioner'], 'values':[0.01783393631,0.4732428049,0.02497602302,0.0385148509,0.167699009,0.277733376]},\n",
    "    'count_house':{'labels':['0', '1', '2+'], 'values':[0.37,0.6,0.03]},\n",
    "    'own_field':{'labels':['YES', 'NO'], 'values':[0.2621335023,0.737866497676384]},\n",
    "    'num_car_house':{'labels':['0', '1', '2', '3+'], 'values':[0.5714285714,0.36,0.06428571429,0.004285714286]},\n",
    "    'own_rent_house':{'labels':['my own', 'rented'], 'values':[0.843,0.157]},\n",
    "    'edu':{'labels':['Educational Sciences', 'Humanities', 'Social, Economic and Legal Sciences', 'Natural Sciences, Mathematics and Informatics', 'Technical Sciences', 'Agricultural Sciences and Veterinary Medicine', 'Health and Sports', 'Arts', 'Security and Defense'], 'values':[0.07591254907,0.0461889827,0.5266633332,0.04571641724,0.1533297557,0.01776640163,0.0930038303,0.02247374859,0.01891291637]},\n",
    "    'temp':{'labels':['Choleric', 'Phlegmatic', 'Sanguine', 'Melancholic'], 'values':[0.38,0.11,0.23,0.28]},\n",
    "    'invest_exp':{'labels':['0', '1-5', '6-10', '11-15', '16-25'], 'values':[0.7,0.2,0.06,0.03,0.01]},\n",
    "    'shares':{'labels':['YES', 'NO'], 'values':[0.003394353314,0.9966056467]},\n",
    "    'corp_oblig':{'labels':['YES', 'NO'], 'values':[0.0003792213936,0.9996207786]},\n",
    "    'oth':{'labels':['YES', 'NO'], 'values':[0.000592597502012084,0.999407402497988]},\n",
    "    'inv_fund':{'labels':['YES', 'NO'], 'values':[0.06491199709,0.9350880029]},\n",
    "    'cash':{'labels':['YES', 'NO'], 'values':[0.04105169923,0.9589483008]},\n",
    "    'crypto':{'labels':['YES', 'NO'], 'values':[0.003284135938,0.9967158641]},\n",
    "    'gov_bond':{'labels':['YES', 'NO'], 'values':[0.06835666691,0.9316433331]},\n",
    "    'deposits':{'labels':['YES', 'NO'], 'values':[0.8180293286,0.1819706714]},\n",
    "    'banking':{'labels':['Online', 'Offline'], 'values':[0.09,0.91]},\n",
    "    'bk_oprat':{'labels':['Up to 7', 'From 8 to 10', 'From 11 to 13', 'From 14 to 18', 'From 19 to more'], 'values':[0.0084,0.2424,0.4729,0.2615,0.0148]},\n",
    "    'bk_dc':{'labels':['Under one', 'One', 'Two', 'Three'], 'values':[0.01,0.57,0.38,0.04]},\n",
    "    'bk_cc':{'labels':['YES', 'NO'], 'values':[0.17,0.83]},\n",
    "    'bk_acc':{'labels':['YES', 'NO'], 'values':[0.8634087377,0.1365912623]},\n",
    "    'ins_prop':{'labels':['YES', 'NO'], 'values':[0.05,0.95]},\n",
    "    'ins_life':{'labels':['YES', 'NO'], 'values':[0.09,0.91]},\n",
    "    'ins_casco':{'labels':['YES', 'NO'], 'values':[0.03,0.97]},\n",
    "    'health_ins':{'labels':['YES', 'NO'], 'values':[0.02,0.98]},\n",
    "    'overdraft':{'labels':['YES', 'NO'], 'values':[0.19,0.81]},\n",
    "    'cons_cred':{'labels':['YES', 'NO'], 'values':[0.26,0.74]},\n",
    "    'mortgage':{'labels':['YES', 'NO'], 'values':[0.02,0.98]},\n",
    "    'car_leas':{'labels':['YES', 'NO'], 'values':[0.2,0.8]},\n",
    "    'pens_ins':{'labels':['YES', 'NO'], 'values':[0.11,0.89]},\n",
    "    'overdraft_app':{'labels':['YES', 'NO'], 'values':[0.2439,0.7561]},\n",
    "    'cons_cred_app':{'labels':['YES', 'NO'], 'values':[0.305299502487562,0.694700497512438]},\n",
    "    'mortgage_app':{'labels':['YES', 'NO'], 'values':[0.03,0.97]},\n",
    "    'bk_cc_app':{'labels':['YES', 'NO'], 'values':[0.21,0.79]}\n",
    "}\n",
    "\n",
    "# Number of rows in the synthetic dataset\n",
    "num_rows = 250000\n",
    "\n",
    "# Create the synthetic dataset\n",
    "dataset = {}\n",
    "for key, value_dict in dists.items():\n",
    "    labels = value_dict['labels']\n",
    "    probabilities = value_dict['values']\n",
    "    \n",
    "    # Normalize probabilities to ensure they sum to 1\n",
    "    normalized_probabilities = probabilities / np.sum(probabilities)\n",
    "    \n",
    "    sampled_values = np.random.choice(labels, size=num_rows, p=normalized_probabilities)\n",
    "    dataset[key] = sampled_values\n",
    "\n",
    "# Printing the first 10 rows of the synthetic dataset\n",
    "# for key in dataset:\n",
    "#     print(f\"{key}: {dataset[key][:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f269b8fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T22:59:55.674099Z",
     "start_time": "2023-07-19T22:59:53.771242Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cat_df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4528f214",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T22:59:55.736979Z",
     "start_time": "2023-07-19T22:59:55.678104Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a201401",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T22:59:55.768431Z",
     "start_time": "2023-07-19T22:59:55.743983Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980b85b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T22:59:55.814967Z",
     "start_time": "2023-07-19T22:59:55.771434Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_df[\"sex\"].value_counts(normalize=True)[\"F\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4a4281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc93386",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T22:59:55.859973Z",
     "start_time": "2023-07-19T22:59:55.819971Z"
    }
   },
   "outputs": [],
   "source": [
    "list(cat_df[\"sex\"].value_counts(normalize=True).index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2344c92f",
   "metadata": {},
   "source": [
    "## Perform a Kolmogorov-Smirnov distribution test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2200934",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T22:59:55.891970Z",
     "start_time": "2023-07-19T22:59:55.863972Z"
    }
   },
   "outputs": [],
   "source": [
    "def kolmogorov_smirnov_test(categorical_data, old_distributions):\n",
    "    \n",
    "    from scipy.stats import ks_2samp\n",
    "    \n",
    "    old = {'sex': {'labels': ['M', 'F'], 'values': [0.4854368932, 0.5145631068]}}\n",
    "    new = {'sex': {'labels': ['M', 'F'], 'values': [0.476, 0.524]}}\n",
    "\n",
    "    statistics = {}\n",
    "    \n",
    "    for col in categorical_data:\n",
    "        \n",
    "        # Extract the values for each category in the old and new distributions\n",
    "        \n",
    "        \n",
    "        old_values = old_distributions[col]['values']\n",
    "        old_labels = old_distributions[col]['labels']\n",
    "        \n",
    "        new_data_labels = list(categorical_data[col].value_counts(normalize=True).index)\n",
    "        \n",
    "        old_dis_data = []\n",
    "        new_dis_data = []\n",
    "        \n",
    "        for i in range(len(old_labels)):\n",
    "            \n",
    "            label = old_labels[i]\n",
    "            old_dis_data.append(old_distributions[col]['values'][i])\n",
    "            \n",
    "            new_data_value = categorical_data[col].value_counts(normalize=True)[label]\n",
    "            new_dis_data.append(new_data_value)\n",
    "        \n",
    "        old_dis_data_array = np.array(old_dis_data)\n",
    "        new_dis_data_array = np.array(new_dis_data)\n",
    "    \n",
    "\n",
    "        # Perform the KS test\n",
    "        ks_statistic, p_value = ks_2samp(old_dis_data_array, new_dis_data_array)\n",
    "\n",
    "        # Define the significance level (alpha) to test against the p-value\n",
    "        alpha = 0.05\n",
    "\n",
    "        # Check if the p-value is less than the significance level\n",
    "        \n",
    "        \n",
    "        if p_value < alpha:\n",
    "            print(f\"Distributions are different for column: {col}\")\n",
    "            \n",
    "            statistics[col] = True\n",
    "        else:\n",
    "            print(f\"Distributions are similar for column: {col}\")\n",
    "            \n",
    "            statistics[col] = False\n",
    "    \n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0d43e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:01.098159Z",
     "start_time": "2023-07-19T22:59:55.896973Z"
    }
   },
   "outputs": [],
   "source": [
    "categorical_ks_statistics = kolmogorov_smirnov_test(categorical_data=cat_df,\n",
    "                                                   old_distributions=dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5025252d",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e7ed35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:07.307402Z",
     "start_time": "2023-07-19T23:00:01.103156Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_df.to_csv(\"df_cat_No_Br_250k_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc8bf26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcac7176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f14c15d",
   "metadata": {},
   "source": [
    "## Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cef055",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:07.337401Z",
     "start_time": "2023-07-19T23:00:07.311403Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "corr = {\n",
    "    'features': ['age', 'ind_risk', 'income', 'pers_exp', 'house_exp', 'taxes', 'transp_telecom', 'hobby'],\n",
    "    'age': [1, -0.00665947056405372, 0.00291644965339247, 0.0107779942638097, 0.00698674581731255, 0.00729153655132963, 0.0099866509330216, 0.00931630696561133],\n",
    "    'ind_risk': [-0.00665947056405372, 1, 0.0039918072709289, 0.00806259039194059, 0.00457023635440603, 0.0061985340641631, 0.00768699810849585, -0.00332322616613201],\n",
    "    'income': [0.00291644965339247, 0.0039918072709289, 1, 0.560949334881676, 0.58892666343229, 0.581907424628933, 0.562946509689962, 0.352350802339294],\n",
    "    'pers_exp': [0.0107779942638097, 0.00806259039194059, 0.560949334881676, 1, 0.928449923861951, 0.929598634668897, 0.934775947642248, 0.714298364869941],\n",
    "    'house_exp': [0.00698674581731255, 0.00457023635440603, 0.58892666343229, 0.928449923861951, 1, 0.93031279279417, 0.927846735467478, 0.679286362990223],\n",
    "    'taxes': [0.00729153655132963, 0.0061985340641631, 0.581907424628933, 0.929598634668897, 0.93031279279417, 1, 0.92920510128812, 0.689442053350162],\n",
    "    'transp_telecom': [0.0099866509330216, 0.00768699810849585, 0.562946509689962, 0.934775947642248, 0.927846735467478, 0.92920510128812, 1, 0.714114127908189],\n",
    "    'hobby': [0.00931630696561133, -0.00332322616613201, 0.352350802339294, 0.714298364869941, 0.679286362990223, 0.689442053350162, 0.714114127908189, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3e9bb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:07.352421Z",
     "start_time": "2023-07-19T23:00:07.341404Z"
    }
   },
   "outputs": [],
   "source": [
    "corr.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e4dd5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:07.368422Z",
     "start_time": "2023-07-19T23:00:07.355403Z"
    }
   },
   "outputs": [],
   "source": [
    "l_corr_matrix = []\n",
    "\n",
    "for k, v in corr.items():\n",
    "    if k == \"features\":\n",
    "        continue\n",
    "    else:\n",
    "        l_corr_matrix.append(v)\n",
    "\n",
    "        \n",
    "arr_corr_matrix = np.array(l_corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1eac74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:07.384401Z",
     "start_time": "2023-07-19T23:00:07.373402Z"
    }
   },
   "outputs": [],
   "source": [
    "print(arr_corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762f63f7",
   "metadata": {},
   "source": [
    "## Generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d03e128",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:07.747232Z",
     "start_time": "2023-07-19T23:00:07.387402Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_bounds = []\n",
    "\n",
    "possible_values = {\n",
    "    'age': [20, 86],\n",
    "    'ind_risk': [0, 1],\n",
    "    'income': [0, 150000],\n",
    "    'pers_exp': [0, 6000],\n",
    "    'house_exp': [0, 4000],\n",
    "    'taxes': [0, 2500],\n",
    "    'transp_telecom': [0, 2500],\n",
    "    'hobby': [0, 3000],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "for v in possible_values.values():\n",
    "    \n",
    "    feature_bounds.append(tuple(v))\n",
    "\n",
    "        \n",
    "mean = []\n",
    "\n",
    "for k, v in possible_values.items():\n",
    "    avg = sum(v)/len(v)\n",
    "    mean.append(avg)  \n",
    "\n",
    "    \n",
    "# std = [int(v/3) for v in mean]\n",
    "std = [3]*8\n",
    "    \n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def generate_synthetic_data_with_bounds(correlation_matrix, num_samples, feature_bounds):\n",
    "    num_features = correlation_matrix.shape[0]\n",
    "    lower_bounds, upper_bounds = zip(*feature_bounds)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "    # Check if the correlation matrix is valid (symmetric and positive definite)\n",
    "    if not np.allclose(correlation_matrix, correlation_matrix.T):\n",
    "        raise ValueError(\"Correlation matrix must be symmetric.\")\n",
    "    if not np.all(np.linalg.eigvals(correlation_matrix) > 0):\n",
    "        raise ValueError(\"Correlation matrix must be positive definite.\")\n",
    "    \n",
    "    # Generate synthetic data using multivariate normal distribution\n",
    "    mean = np.zeros(num_features)\n",
    "    synthetic_data = np.random.multivariate_normal(mean, correlation_matrix, num_samples)\n",
    "    \n",
    "    # Apply Gaussian copula to maintain correlation structure\n",
    "    synthetic_data = norm.cdf(synthetic_data, loc=mean, scale=std)\n",
    "    \n",
    "    # Scale the data to the specified bounds for each feature\n",
    "    for i in range(num_features):\n",
    "        synthetic_data[:, i] = lower_bounds[i] + synthetic_data[:, i] * (upper_bounds[i] - lower_bounds[i])\n",
    "    \n",
    "    return synthetic_data\n",
    "\n",
    "# Example usage:\n",
    "correlation_matrix = np.array(l_corr_matrix)\n",
    "\n",
    "num_samples = 250000\n",
    "\n",
    "synthetic_data = generate_synthetic_data_with_bounds(correlation_matrix, num_samples, feature_bounds)\n",
    "print(synthetic_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d21d85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:07.778504Z",
     "start_time": "2023-07-19T23:00:07.750233Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "adjusted_df = pd.DataFrame(synthetic_data, columns=possible_values.keys())\n",
    "adjusted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f30620",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:07.841295Z",
     "start_time": "2023-07-19T23:00:07.781448Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f5f99f",
   "metadata": {},
   "source": [
    "## Plot distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467a58df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:08.090775Z",
     "start_time": "2023-07-19T23:00:07.845274Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def plot_distribution(data, column_name):\n",
    "    \"\"\"\n",
    "    Plots the distribution of a pandas column using Plotly.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The pandas DataFrame containing the data.\n",
    "        column_name (str): The name of the column to plot.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Ensure the column exists in the DataFrame\n",
    "    if column_name not in data.columns:\n",
    "        raise ValueError(f\"Column '{column_name}' not found in the DataFrame.\")\n",
    "\n",
    "    # Use Plotly Express to plot the distribution\n",
    "    fig = px.histogram(data, x=column_name, nbins=50, title=f'Distribution of {column_name}')\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edab1ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:21.072398Z",
     "start_time": "2023-07-19T23:00:08.094756Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in adjusted_df.columns:\n",
    "    plot_distribution(adjusted_df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc4ae3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d00f53e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15746c69",
   "metadata": {},
   "source": [
    "## Plot the two correlation matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8c7108",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:21.088394Z",
     "start_time": "2023-07-19T23:00:21.077395Z"
    }
   },
   "outputs": [],
   "source": [
    "possible_values.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c86ddc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:21.782493Z",
     "start_time": "2023-07-19T23:00:21.092437Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (Code from the previous answer)\n",
    "\n",
    "# Calculate the correlation matrix for the adjusted DataFrame\n",
    "correlation_matrix_adjusted = adjusted_df.corr()\n",
    "\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(\"Adjusted Correlation Matrix:\")\n",
    "print(correlation_matrix_adjusted)\n",
    "\n",
    "# Convert the original correlation data (corr) to a DataFrame\n",
    "original_corr_df = pd.DataFrame(corr)\n",
    "original_corr_df.set_index('features', inplace=True)\n",
    "\n",
    "# Display the original correlation data\n",
    "print(\"\\nOriginal Correlation Matrix:\")\n",
    "print(original_corr_df)\n",
    "\n",
    "# Plot the correlation matrix heatmaps for both adjusted and original data side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle(\"Comparison of Correlation Matrices\", fontsize=16)\n",
    "\n",
    "# Adjusted correlation matrix heatmap\n",
    "axes[0].imshow(correlation_matrix_adjusted, cmap='coolwarm', interpolation='nearest')\n",
    "axes[0].set_xticks(np.arange(len(correlation_matrix_adjusted)))\n",
    "axes[0].set_yticks(np.arange(len(correlation_matrix_adjusted)))\n",
    "axes[0].set_xticklabels(correlation_matrix_adjusted.columns, rotation=45)\n",
    "axes[0].set_yticklabels(correlation_matrix_adjusted.columns)\n",
    "axes[0].set_title(\"Adjusted Correlation Matrix\")\n",
    "\n",
    "# Original correlation matrix heatmap\n",
    "axes[1].imshow(original_corr_df, cmap='coolwarm', interpolation='nearest')\n",
    "axes[1].set_xticks(np.arange(len(original_corr_df)))\n",
    "axes[1].set_yticks(np.arange(len(original_corr_df)))\n",
    "axes[1].set_xticklabels(original_corr_df.columns, rotation=45)\n",
    "axes[1].set_yticklabels(original_corr_df.columns)\n",
    "axes[1].set_title(\"Original Correlation Matrix\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19039758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2908b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:21.798147Z",
     "start_time": "2023-07-19T23:00:21.786589Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to measure the distance between two correlation matrices using Frobenius norm\n",
    "def correlation_distance(matrix1, matrix2):\n",
    "    return np.linalg.norm(matrix1 - matrix2, ord='fro')\n",
    "\n",
    "\n",
    "current_distance = correlation_distance(matrix1=correlation_matrix_adjusted, matrix2=original_corr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6126576b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:21.829706Z",
     "start_time": "2023-07-19T23:00:21.812707Z"
    }
   },
   "outputs": [],
   "source": [
    "current_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c842bd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "130e5bad",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d65004",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:26.479596Z",
     "start_time": "2023-07-19T23:00:21.832711Z"
    }
   },
   "outputs": [],
   "source": [
    "adjusted_df.to_csv(\"adjusted_df_num_No_BR_250k_v3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b60b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15c6a759",
   "metadata": {},
   "source": [
    "## Combine the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a750f708",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:26.494858Z",
     "start_time": "2023-07-19T23:00:26.483237Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31f5f29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:29.081707Z",
     "start_time": "2023-07-19T23:00:26.501365Z"
    }
   },
   "outputs": [],
   "source": [
    "num_df = pd.read_csv(\"adjusted_df_num_No_BR_250k.csv\", index_col=[0])\n",
    "cat_df = pd.read_csv(\"df_cat_No_Br_250k.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c0771e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:29.160391Z",
     "start_time": "2023-07-19T23:00:29.086245Z"
    }
   },
   "outputs": [],
   "source": [
    "df_merged = pd.concat([num_df, cat_df], axis=1)\n",
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f0edd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:29.223326Z",
     "start_time": "2023-07-19T23:00:29.164231Z"
    }
   },
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e37b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "338fe1cd",
   "metadata": {},
   "source": [
    "## Apply the business rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed177786",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:29.239329Z",
     "start_time": "2023-07-19T23:00:29.227327Z"
    }
   },
   "outputs": [],
   "source": [
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ae2ea8",
   "metadata": {},
   "source": [
    "**INVESTMENT IN STOCKS NOT FOUND!!!**\n",
    "<br> Currency investments means - cash??\n",
    "<br> Investment in government securities??\n",
    "<br> Investment in stocks??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdadf326",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:31.271462Z",
     "start_time": "2023-07-19T23:00:29.243327Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Business rules as a list of dictionaries\n",
    "full_business_rules = [\n",
    "    {\"Independent feature\": \"marit_stat\", \"Independent feature value\": \"=='Married'\", \"Dependent feature\": \"house_memb\", \"Dependent feature value filter\": \">'2'\", \"Note\": \"The number of household members in family households is more likely to be greater than 2\"},\n",
    "    {\"Independent feature\": \"prof_ind\", \"Independent feature value\": \"=='Financial and administrative activities'\", \"Dependent feature\": \"invest_exp\", \"Dependent feature value filter\": \">'0'\", \"Note\": \"They are more likely to own a bank account\"},\n",
    "    {\"Independent feature\": \"age\", \"Independent feature value\": \"<25\", \"Dependent feature\": \"invest_exp\", \"Dependent feature value filter\": \"=='0'\", \"Note\": \"Under 24s are less likely to have investment experience. Between 35-44 and 45-54 are more likely to have extensive investment experience\"},\n",
    "    {\"Independent feature\": \"age\", \"Independent feature value\": \"<25\", \"Dependent feature\": \"lv_educ\", \"Dependent feature value filter\": \"!='Higher'\", \"Note\": \"Under 24s are less likely to have a college degree\"},\n",
    "    {\"Independent feature\": \"age\", \"Independent feature value\": \"<25\", \"Dependent feature\": \"chil_u_18_y\", \"Dependent feature value filter\": \"<'2'\", \"Note\": \"From 20-24, it is less likely to have more than 1 child under 18\"},\n",
    "    {\"Independent feature\": \"invest_exp\", \"Independent feature value\": \">'0'\", \"Dependent feature\": \"deposits\", \"Dependent feature value filter\": \"=='Y'\", \"Note\": \"They are more likely to own a bank account\"},\n",
    "    {\"Independent feature\": \"shares\", \"Independent feature value\": \"=='Y'\", \"Dependent feature\": \"invest_exp\", \"Dependent feature value filter\": \">'0'\", \"Note\": \"Previous investment experience in years\"},\n",
    "    {\"Independent feature\": \"corp_oblig\", \"Independent feature value\": \"=='Y'\", \"Dependent feature\": \"invest_exp\", \"Dependent feature value filter\": \">'0'\", \"Note\": \"Previous investment experience in years\"},\n",
    "    {\"Independent feature\": \"oth\", \"Independent feature value\": \"=='Y'\", \"Dependent feature\": \"invest_exp\", \"Dependent feature value filter\": \">'0'\", \"Note\": \"Previous investment experience in years\"},\n",
    "    {\"Independent feature\": \"inv_fund\", \"Independent feature value\": \"=='Y'\", \"Dependent feature\": \"invest_exp\", \"Dependent feature value filter\": \">'0'\", \"Note\": \"Previous investment experience in years\"},\n",
    "    {\"Independent feature\": \"cash\", \"Independent feature value\": \"=='Y'\", \"Dependent feature\": \"invest_exp\", \"Dependent feature value filter\": \">'0'\", \"Note\": \"Previous investment experience in years\"},\n",
    "    {\"Independent feature\": \"crypto\", \"Independent feature value\": \"=='Y'\", \"Dependent feature\": \"invest_exp\", \"Dependent feature value filter\": \">'0'\", \"Note\": \"Previous investment experience in years\"},\n",
    "    {\"Independent feature\": \"gov_bond\", \"Independent feature value\": \"=='Y'\", \"Dependent feature\": \"invest_exp\", \"Dependent feature value filter\": \">'0'\", \"Note\": \"Previous investment experience in years\"},\n",
    "    {\"Independent feature\": \"age\", \"Independent feature value\": \"<25\", \"Dependent feature\": \"bk_acc\", \"Dependent feature value filter\": \"=='N'\", \"Note\": \"Under 24s are less likely to have a checking account\"},\n",
    "    {\"Independent feature\": \"age\", \"Independent feature value\": \"<18\", \"Dependent feature\": \"bk_acc\", \"Dependent feature value filter\": \"=='N'\", \"Note\": \"Under 18 is not possible to have a current account\"},\n",
    "    {\"Independent feature\": \"lv_educ\", \"Independent feature value\": \"=='Higher'\", \"Dependent feature\": \"income\", \"Dependent feature value filter\": \">27601\", \"Note\": \"A higher level of education implies earnings in the upper range\"},\n",
    "    {\"Independent feature\": \"chil_u_18_y\", \"Independent feature value\": \">'1'\", \"Dependent feature\": \"house_memb\", \"Dependent feature value filter\": \">'3'\", \"Note\": \"The number of household members is directly dependent on the number of children under 18\"},\n",
    "    {\"Independent feature\": \"lv_educ\", \"Independent feature value\": \"=='Higher'\", \"Dependent feature\": \"soc_econ_stat\", \"Dependent feature value filter\": \"=='Economically active'\", \"Note\": \"A higher level of education implies an economically active status\"},\n",
    "    {\"Independent feature\": \"income\", \"Independent feature value\": \">27601\", \"Dependent feature\": \"taxes\", \"Dependent feature value filter\": \">2500\", \"Note\": \"Earnings in the upper range correspond to higher taxes and insurance\"},\n",
    "]\n",
    "\n",
    "\n",
    "# Function to apply a single business rule\n",
    "def apply_business_rule(rule, dataframe):\n",
    "    independent_feature = rule[\"Independent feature\"]\n",
    "    independent_feature_value = rule[\"Independent feature value\"]\n",
    "    dependent_feature = rule[\"Dependent feature\"]\n",
    "    dependent_feature_value_filter = rule[\"Dependent feature value filter\"]\n",
    "\n",
    "    # Construct the filter condition dynamically using f-strings\n",
    "#     filter_condition = f\"(dataframe['marit_stat'] == 'Married') & (dataframe['house_memb'] > {dependent_feature_value_filter})\"\n",
    "#     filter_condition = f\"(dataframe['age'] {independent_feature_value}) & (dataframe['invest_exp']  {dependent_feature_value_filter})\"\n",
    "#         ({independent_feature} {independent_feature_value}) & ({dependent_feature} {dependent_feature_value_filter}))\"\n",
    "\n",
    "    filter_condition = f\"[(dataframe['{independent_feature}'] {independent_feature_value}) & (dataframe['{dependent_feature}'] {dependent_feature_value_filter})]\"   \n",
    "#     [(df_merged['marit_stat'] =='Married') & (df_merged['house_memb'] >'2')]\n",
    "    \n",
    "    print(\"filter_condition: \", filter_condition)\n",
    "    \n",
    "    list_mask = eval(filter_condition)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Apply the filter condition to the DataFrame\n",
    "#     filtered_df = df_merged.loc[eval(filter_condition)]\n",
    "    filtered_df = df_merged[list_mask[0]]\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# Apply all business rules to the DataFrame\n",
    "filtered_dfs = []\n",
    "for rule in full_business_rules:\n",
    "#     print(\"Rule: \", rule)\n",
    "    df_filtered = apply_business_rule(rule, df_merged)\n",
    "    \n",
    "    # CHECK DISTRIBUTION OF THE NEW INDEPENDENT VARIABLE\n",
    "    # CHECK DISTRIBUTION OF THE OLD INDEPENDENT VARIABLE\n",
    "    \n",
    "    # IF DIFFERENT\n",
    "        # ADJUST THE NEW ONE TO FOLLOW THE OLD ONE\n",
    "        \n",
    "    # DO THE SAME WITH THE DEPENDENT VARIABLE\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    filtered_dfs.append(df_filtered)\n",
    "\n",
    "# Concatenate all filtered DataFrames\n",
    "all_filtered_dfs = pd.concat(filtered_dfs)\n",
    "df_BR_applied = all_filtered_dfs.drop_duplicates()\n",
    "\n",
    "# print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab71b8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:31.366307Z",
     "start_time": "2023-07-19T23:00:31.275306Z"
    }
   },
   "outputs": [],
   "source": [
    "df_BR_applied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca38e98",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e3112",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:36.360345Z",
     "start_time": "2023-07-19T23:00:31.369308Z"
    }
   },
   "outputs": [],
   "source": [
    "df_BR_applied.to_csv(\"df_BR_applied_v1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdd6287",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3c6bec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:37.996478Z",
     "start_time": "2023-07-19T23:00:36.364463Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df_BR_applied_v1.csv\", index_col=\"Unnamed: 0\")\n",
    "data_sample = df.sample(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92070d58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.027767Z",
     "start_time": "2023-07-19T23:00:37.999482Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"mortgage\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71566449",
   "metadata": {},
   "source": [
    "## Generate new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0f7cc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.059371Z",
     "start_time": "2023-07-19T23:00:38.031248Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_new_features(data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c95dd71",
   "metadata": {},
   "source": [
    "## Adjust current features (cleaning, imputing, deleting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8178ac21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.074390Z",
     "start_time": "2023-07-19T23:00:38.063369Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_features(data):\n",
    "    pass\n",
    "\n",
    "def impute_features(data):\n",
    "    pass\n",
    "\n",
    "def del_features(data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e645a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0fec3b6",
   "metadata": {},
   "source": [
    "## Split on categorical and numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff7aaf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877841c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3ab2edb",
   "metadata": {},
   "source": [
    "## Data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9f750a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.090367Z",
     "start_time": "2023-07-19T23:00:38.077375Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_cols = list(dists.keys())\n",
    "print(\"few categorical columns: \", cat_cols[:5])\n",
    "num_cols = [col for col in df.columns if col not in cat_cols]\n",
    "print(\"few numerical columns: \", num_cols[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dac65e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.106389Z",
     "start_time": "2023-07-19T23:00:38.094370Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_encoding(data, categorical_cols):\n",
    "    \n",
    "    return pd.get_dummies(data, columns=categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54343327",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.170449Z",
     "start_time": "2023-07-19T23:00:38.109370Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_data_sample = data_encoding(data_sample, categorical_cols=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cbdb0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.282001Z",
     "start_time": "2023-07-19T23:00:38.173996Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06416da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.297785Z",
     "start_time": "2023-07-19T23:00:38.285001Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_data_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af791168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "422eb156",
   "metadata": {},
   "source": [
    "## Feature scaling (data standardization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770da2e5",
   "metadata": {},
   "source": [
    "min-max scaling and standardization (z-score normalization)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614d6f84",
   "metadata": {},
   "source": [
    "### Split the data into numerical and categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f1bad0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.344627Z",
     "start_time": "2023-07-19T23:00:38.301348Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_split_cat_num(data, numerical_cols):\n",
    "    \n",
    "    num_data = data[numerical_cols]\n",
    "    cat_cols = [col for col in data.columns if col not in numerical_cols]\n",
    "    cat_data = data[cat_cols]\n",
    "    \n",
    "    cat_data.reset_index(inplace=True)\n",
    "    num_data.reset_index(inplace=True)\n",
    "    return cat_data, num_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45f4dfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.360626Z",
     "start_time": "2023-07-19T23:00:38.348609Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_cat_data, encoded_num_data = data_split_cat_num(data=encoded_data_sample, \n",
    "                                                       numerical_cols=num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d41852",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.456610Z",
     "start_time": "2023-07-19T23:00:38.363626Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_cat_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9db4e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.487953Z",
     "start_time": "2023-07-19T23:00:38.460610Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_num_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61646750",
   "metadata": {},
   "source": [
    "### TODO adjust the function below; Should work only with Num features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239dcee3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.503953Z",
     "start_time": "2023-07-19T23:00:38.491952Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_standardization(data):\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    # Initialize the StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit and transform the DataFrame to perform standardization\n",
    "    standardized_df = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "    \n",
    "    return standardized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ef0faf",
   "metadata": {},
   "source": [
    "test standardization with all features (not just the numerical ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e239e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.519952Z",
     "start_time": "2023-07-19T23:00:38.507953Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_data_sample_standardized_numerical = data_standardization(encoded_num_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bf3c42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.645617Z",
     "start_time": "2023-07-19T23:00:38.524953Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_cat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4940e10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.677619Z",
     "start_time": "2023-07-19T23:00:38.649620Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_data_sample_standardized_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f12593f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.692619Z",
     "start_time": "2023-07-19T23:00:38.681620Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_data_sample_standardized = pd.concat([encoded_cat_data, encoded_data_sample_standardized_numerical],\n",
    "                                            axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569ba239",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.707640Z",
     "start_time": "2023-07-19T23:00:38.696622Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_data_sample_standardized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b957bc0d",
   "metadata": {},
   "source": [
    "## Delete binary cols (columns that have only two possible options as values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570536d0",
   "metadata": {},
   "source": [
    "Will keep only the \"YES\" features (e.g. mortgage_YES - a value of 1 here means the client wants to have a mortgage, 0 - otherwise) to reduce the size of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51e63e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.723617Z",
     "start_time": "2023-07-19T23:00:38.710617Z"
    }
   },
   "outputs": [],
   "source": [
    "def del_NO_cols(data, additional_cols_to_del=['banking_Offline', 'own_rent_house_my own', 'soc_econ_stat_Economically inactive', 'sex_F']):\n",
    "    \n",
    "    # select all \"_NO\" columns \n",
    "    cols_to_del = list(data.filter(regex='_NO$').columns)\n",
    "    \n",
    "    # and extend the list with additional columns to be deleted\n",
    "    cols_to_del.extend(additional_cols_to_del)\n",
    "    \n",
    "    reduced_data = data.drop(cols_to_del, axis=1)\n",
    "    \n",
    "    return reduced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd7d253",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.739619Z",
     "start_time": "2023-07-19T23:00:38.727616Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_data_sample_reduced = del_NO_cols(encoded_data_sample_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e392de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.755640Z",
     "start_time": "2023-07-19T23:00:38.743621Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_data_sample_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19e5a0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.835175Z",
     "start_time": "2023-07-19T23:00:38.759623Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_data_sample_reduced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d526eef4",
   "metadata": {},
   "source": [
    "## Split data - predictors and target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21f26ab",
   "metadata": {},
   "source": [
    "Target features:\n",
    "\n",
    "    Overdraft\n",
    "    Consumer credit\n",
    "    Mortgage loan\n",
    "    Credit card\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178bbe23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.851196Z",
     "start_time": "2023-07-19T23:00:38.838182Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_data_sample_reduced.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05187cee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.867177Z",
     "start_time": "2023-07-19T23:00:38.855185Z"
    }
   },
   "outputs": [],
   "source": [
    "target_columns = [\"overdraft_YES\", \"cons_cred_YES\", \"mortgage_YES\", \"bk_cc_YES\"]\n",
    "\n",
    "def split_pred_target(data, target_cols):\n",
    "\n",
    "    predictor_cols = [col for col in data.columns if col not in target_cols]\n",
    "\n",
    "    \n",
    "    X_data = data[predictor_cols]\n",
    "    y_data = data[target_cols]\n",
    "\n",
    "    return X_data, y_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04065ffe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.883196Z",
     "start_time": "2023-07-19T23:00:38.871176Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = split_pred_target(data=encoded_data_sample_reduced, target_cols=target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34171fb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.899196Z",
     "start_time": "2023-07-19T23:00:38.886199Z"
    }
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e85651",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.931238Z",
     "start_time": "2023-07-19T23:00:38.902178Z"
    }
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b24c23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.947264Z",
     "start_time": "2023-07-19T23:00:38.934249Z"
    }
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6938bc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.963333Z",
     "start_time": "2023-07-19T23:00:38.951250Z"
    }
   },
   "outputs": [],
   "source": [
    "y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4288347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7c48aed",
   "metadata": {},
   "source": [
    "## Split data on train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf7da50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.979306Z",
     "start_time": "2023-07-19T23:00:38.967293Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4c4cba",
   "metadata": {},
   "source": [
    "## Balance the data (target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c763bb0",
   "metadata": {},
   "source": [
    "Multiple ways to do that:\n",
    "- SMOTE\n",
    "- **TODO** RandomOverSampler with correlation-aware sampling (ROS-CAS)\n",
    "\n",
    "\n",
    "Will split y_train into four different y_trains for each category. The idea is that we'll have four separate models in the end that are going to make predictions for each class separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7821f430",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98f9b22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:38.995306Z",
     "start_time": "2023-07-19T23:00:38.982288Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "y_train_overdraft = y_train[\"overdraft_YES\"]\n",
    "y_train_cons_cred = y_train[\"cons_cred_YES\"]\n",
    "y_train_mortgage  = y_train[\"mortgage_YES\"]\n",
    "y_train_bk_cc     = y_train[\"bk_cc_YES\"]\n",
    "\n",
    "\n",
    "\n",
    "y_test_overdraft = y_test[\"overdraft_YES\"]\n",
    "y_test_cons_cred = y_test[\"cons_cred_YES\"]\n",
    "y_test_mortgage  = y_test[\"mortgage_YES\"]\n",
    "y_test_bk_cc     = y_test[\"bk_cc_YES\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d94d70",
   "metadata": {},
   "source": [
    "#### Try with 4 different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ab59b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:39.011306Z",
     "start_time": "2023-07-19T23:00:38.998285Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train_overdraft.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a826296",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:39.027306Z",
     "start_time": "2023-07-19T23:00:39.015287Z"
    }
   },
   "outputs": [],
   "source": [
    "def oversample_with_SMOTE(train_X, train_y):\n",
    "    \n",
    "\n",
    "    os = SMOTE(random_state=42)\n",
    "\n",
    "    os_X_tr, os_y_tr = os.fit_resample(train_X, train_y)\n",
    "    # TODO ...the rest to follow later\n",
    "\n",
    "    df_os_X_tr = pd.DataFrame(data=os_X_tr ,columns=train_X.columns)\n",
    "    df_os_y_tr = pd.DataFrame(data=os_y_tr, columns=[train_y.name])\n",
    "\n",
    "\n",
    "    # check old and new distributions:\n",
    "    print(\"Original data target distributions:\")\n",
    "    print(train_y.value_counts())\n",
    "    print()\n",
    "    print()\n",
    "    print(\"Oversampled data target distributions:\")\n",
    "    print(df_os_y_tr.value_counts())\n",
    "    \n",
    "    \n",
    "    return df_os_X_tr, df_os_y_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12295107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:39.280297Z",
     "start_time": "2023-07-19T23:00:39.031309Z"
    }
   },
   "outputs": [],
   "source": [
    "df_os_X_train_overdraft, df_os_y_train_overdraft = oversample_with_SMOTE(train_X=X_train, train_y=y_train_overdraft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130c0de3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:39.296297Z",
     "start_time": "2023-07-19T23:00:39.284297Z"
    }
   },
   "outputs": [],
   "source": [
    "df_os_y_train_overdraft.values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c1e396",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3087c47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:39.343028Z",
     "start_time": "2023-07-19T23:00:39.299820Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_sel():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb3f7fb",
   "metadata": {},
   "source": [
    "# Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112df902",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:39.359029Z",
     "start_time": "2023-07-19T23:00:39.347029Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "lg1 = LogisticRegression(random_state=42, max_iter=1000, class_weight=None)\n",
    "\n",
    "\n",
    "def model_predict(model, train_X, train_y, test_X, test_y):\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, recall_score\n",
    "    \n",
    "    # extract values\n",
    "    train_y_values = train_y.values.flatten() \n",
    "    \n",
    "    # fit it\n",
    "    model.fit(train_X, train_y_values)\n",
    "    \n",
    "    # test\n",
    "    pred_y = model.predict(test_X)# performance\n",
    "    print(f'Accuracy Score: {accuracy_score(test_y, pred_y)}')\n",
    "    print(f'Confusion Matrix: \\n{confusion_matrix(test_y, pred_y)}')\n",
    "    print(f'Area Under Curve: {roc_auc_score(test_y, pred_y)}')\n",
    "    print(f'Recall score: {recall_score(test_y, pred_y)}')\n",
    "    \n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2882fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T23:00:39.405028Z",
     "start_time": "2023-07-19T23:00:39.363028Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_y_overdraft = model_predict(model=lg1,\n",
    "                                train_X=df_os_X_train_overdraft,\n",
    "                                train_y=df_os_y_train_overdraft,\n",
    "                                test_X=X_test,\n",
    "                                test_y=y_test_overdraft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2c7327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baec32d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "592255fb",
   "metadata": {},
   "source": [
    "## Analyse feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3b7d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b542f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57ad342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce6861a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba80f8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bf792f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a734088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c04397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29969197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49bd398d",
   "metadata": {},
   "source": [
    "# Alternative tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f483b79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T21:39:45.908844Z",
     "start_time": "2023-07-19T21:39:45.894821Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "corr = {\n",
    "    'features': ['age', 'ind_risk', 'income', 'pers_exp', 'house_exp', 'taxes', 'transp_telecom', 'hobby'],\n",
    "    'age': [1, -0.00665947056405372, 0.00291644965339247, 0.0107779942638097, 0.00698674581731255, 0.00729153655132963, 0.0099866509330216, 0.00931630696561133],\n",
    "    'ind_risk': [-0.00665947056405372, 1, 0.0039918072709289, 0.00806259039194059, 0.00457023635440603, 0.0061985340641631, 0.00768699810849585, -0.00332322616613201],\n",
    "    'income': [0.00291644965339247, 0.0039918072709289, 1, 0.560949334881676, 0.58892666343229, 0.581907424628933, 0.562946509689962, 0.352350802339294],\n",
    "    'pers_exp': [0.0107779942638097, 0.00806259039194059, 0.560949334881676, 1, 0.928449923861951, 0.929598634668897, 0.934775947642248, 0.714298364869941],\n",
    "    'house_exp': [0.00698674581731255, 0.00457023635440603, 0.58892666343229, 0.928449923861951, 1, 0.93031279279417, 0.927846735467478, 0.679286362990223],\n",
    "    'taxes': [0.00729153655132963, 0.0061985340641631, 0.581907424628933, 0.929598634668897, 0.93031279279417, 1, 0.92920510128812, 0.689442053350162],\n",
    "    'transp_telecom': [0.0099866509330216, 0.00768699810849585, 0.562946509689962, 0.934775947642248, 0.927846735467478, 0.92920510128812, 1, 0.714114127908189],\n",
    "    'hobby': [0.00931630696561133, -0.00332322616613201, 0.352350802339294, 0.714298364869941, 0.679286362990223, 0.689442053350162, 0.714114127908189, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653f8b7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T21:39:46.081553Z",
     "start_time": "2023-07-19T21:39:46.067555Z"
    }
   },
   "outputs": [],
   "source": [
    "l_corr_matrix = []\n",
    "\n",
    "for k, v in corr.items():\n",
    "    if k == \"features\":\n",
    "        continue\n",
    "    else:\n",
    "        l_corr_matrix.append(v)\n",
    "\n",
    "        \n",
    "arr_corr_matrix = np.array(l_corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca93133c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T21:39:46.237554Z",
     "start_time": "2023-07-19T21:39:46.224553Z"
    }
   },
   "outputs": [],
   "source": [
    "# def generate_correlated_random_variables(mean, covariance, num_samples):\n",
    "#     L = np.linalg.cholesky(covariance)\n",
    "    \n",
    "#     # TO BE REPLACED BY DATA GENERATED FROM THE OLD FUNCTION THAT RESPECTS THE BOUNDARIES (generate_synthetic_data_with_bounds)\n",
    "#     normal_samples = np.random.normal(size=(num_samples, covariance.shape[0]))\n",
    "#     print(\"normal_samples shape\", normal_samples.shape)\n",
    "#     return mean + np.dot(normal_samples, L.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ab8213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T21:41:13.707169Z",
     "start_time": "2023-07-19T21:41:13.691170Z"
    }
   },
   "outputs": [],
   "source": [
    "# n_samples = 10000\n",
    "\n",
    "# samples = generate_correlated_random_variables(mean=mean,\n",
    "#                                                covariance=arr_corr_matrix,\n",
    "#                                                num_samples=n_samples)\n",
    "# df_test = pd.DataFrame(samples, columns=possible_values.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4a85de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e31b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e12129",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T22:01:53.800801Z",
     "start_time": "2023-07-19T22:01:53.782778Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from scipy.stats import norm\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# def generate_synthetic_data_with_bounds(correlation_matrix, num_samples, feature_bounds):\n",
    "#     num_features = correlation_matrix.shape[0]\n",
    "#     lower_bounds, upper_bounds = zip(*feature_bounds)\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "#     # Check if the correlation matrix is valid (symmetric and positive definite)\n",
    "#     if not np.allclose(correlation_matrix, correlation_matrix.T):\n",
    "#         raise ValueError(\"Correlation matrix must be symmetric.\")\n",
    "#     if not np.all(np.linalg.eigvals(correlation_matrix) > 0):\n",
    "#         raise ValueError(\"Correlation matrix must be positive definite.\")\n",
    "    \n",
    "#     # Generate synthetic data using multivariate normal distribution\n",
    "#     mean = np.zeros(num_features)\n",
    "#     synthetic_data = np.random.multivariate_normal(mean, correlation_matrix, num_samples)\n",
    "    \n",
    "#     # Apply Gaussian copula to maintain correlation structure\n",
    "#     synthetic_data = norm.cdf(synthetic_data)\n",
    "    \n",
    "#     # Scale the data to the specified bounds for each feature\n",
    "#     for i in range(num_features):\n",
    "#         synthetic_data[:, i] = lower_bounds[i] + synthetic_data[:, i] * (upper_bounds[i] - lower_bounds[i])\n",
    "    \n",
    "#     return synthetic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6f710a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T22:02:45.865530Z",
     "start_time": "2023-07-19T22:02:45.848140Z"
    }
   },
   "outputs": [],
   "source": [
    "# feature_bounds = []\n",
    "\n",
    "# possible_values = {\n",
    "#     'age': [20, 86],\n",
    "#     'ind_risk': [0, 1],\n",
    "#     'income': [0, 150000],\n",
    "#     'pers_exp': [0, 6000],\n",
    "#     'house_exp': [0, 4000],\n",
    "#     'taxes': [0, 2500],\n",
    "#     'transp_telecom': [0, 2500],\n",
    "#     'hobby': [0, 3000],\n",
    "# }\n",
    "\n",
    "\n",
    "# for v in possible_values.values():\n",
    "    \n",
    "#     feature_bounds.append(tuple(v))\n",
    "\n",
    "# # Outcome of (generate_synthetic_data_with_bounds) goes as synthetic_samples in the following function\n",
    "\n",
    "# # Example usage:\n",
    "# correlation_matrix = np.array(l_corr_matrix)\n",
    "\n",
    "# num_samples = 10000\n",
    "\n",
    "# synthetic_samp = generate_synthetic_data_with_bounds(correlation_matrix=correlation_matrix, \n",
    "#                                                      num_samples=num_samples, \n",
    "#                                                      feature_bounds=feature_bounds)\n",
    "\n",
    "# mean = []\n",
    "\n",
    "# for k, v in possible_values.items():\n",
    "#     avg = sum(v)/len(v)\n",
    "#     mean.append(avg)  \n",
    "\n",
    "    \n",
    "# print(\"mean\", mean)\n",
    "\n",
    "# def generate_correlated_random_variables_V2(mean, \n",
    "#                                             covariance, \n",
    "#                                             synthetic_samples):\n",
    "    \n",
    "    \n",
    "#     L = np.linalg.cholesky(covariance)\n",
    "#     print(\"normal_samples shape\", synthetic_samples.shape)\n",
    "#     return mean + np.dot(synthetic_samples, L.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2ddae8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T22:01:54.149485Z",
     "start_time": "2023-07-19T22:01:54.135485Z"
    }
   },
   "outputs": [],
   "source": [
    "# samples = generate_correlated_random_variables_V2(mean=mean, \n",
    "#                                             covariance=correlation_matrix, \n",
    "#                                             synthetic_samples=synthetic_samp)\n",
    "# df_test = pd.DataFrame(samples, columns=possible_values.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f85a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T21:16:38.511459Z",
     "start_time": "2023-07-19T21:16:38.038428Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065d1ee0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T22:01:55.286646Z",
     "start_time": "2023-07-19T22:01:55.267118Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check the correlation of the generated variables\n",
    "correlation = df_test.corr()\n",
    "print(\"Correlation matrix:\")\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfa81a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T22:01:56.390467Z",
     "start_time": "2023-07-19T22:01:56.019467Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the distribution of the generated variables\n",
    "sns.jointplot(x='age', y='income', data=df_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eed15f",
   "metadata": {},
   "source": [
    "## Plot distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d797fe16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T22:02:00.595049Z",
     "start_time": "2023-07-19T22:02:00.580522Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def plot_distribution(data, column_name):\n",
    "    \"\"\"\n",
    "    Plots the distribution of a pandas column using Plotly.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The pandas DataFrame containing the data.\n",
    "        column_name (str): The name of the column to plot.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Ensure the column exists in the DataFrame\n",
    "    if column_name not in data.columns:\n",
    "        raise ValueError(f\"Column '{column_name}' not found in the DataFrame.\")\n",
    "\n",
    "    # Use Plotly Express to plot the distribution\n",
    "    fig = px.histogram(data, x=column_name, nbins=50, title=f'Distribution of {column_name}')\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714415f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T22:02:01.241313Z",
     "start_time": "2023-07-19T22:02:00.770314Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in df_test.columns:\n",
    "    plot_distribution(df_test, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fae63de",
   "metadata": {},
   "source": [
    "## Plot the two correlation matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028c560c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T21:41:42.809584Z",
     "start_time": "2023-07-19T21:41:42.607008Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (Code from the previous answer)\n",
    "\n",
    "# Calculate the correlation matrix for the adjusted DataFrame\n",
    "correlation_matrix_adjusted = df_test.corr()\n",
    "\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(\"Adjusted Correlation Matrix:\")\n",
    "print(correlation_matrix_adjusted)\n",
    "\n",
    "# Convert the original correlation data (corr) to a DataFrame\n",
    "original_corr_df = pd.DataFrame(corr)\n",
    "original_corr_df.set_index('features', inplace=True)\n",
    "\n",
    "# Display the original correlation data\n",
    "print(\"\\nOriginal Correlation Matrix:\")\n",
    "print(original_corr_df)\n",
    "\n",
    "# Plot the correlation matrix heatmaps for both adjusted and original data side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle(\"Comparison of Correlation Matrices\", fontsize=16)\n",
    "\n",
    "# Adjusted correlation matrix heatmap\n",
    "axes[0].imshow(correlation_matrix_adjusted, cmap='coolwarm', interpolation='nearest')\n",
    "axes[0].set_xticks(np.arange(len(correlation_matrix_adjusted)))\n",
    "axes[0].set_yticks(np.arange(len(correlation_matrix_adjusted)))\n",
    "axes[0].set_xticklabels(correlation_matrix_adjusted.columns, rotation=45)\n",
    "axes[0].set_yticklabels(correlation_matrix_adjusted.columns)\n",
    "axes[0].set_title(\"Adjusted Correlation Matrix\")\n",
    "\n",
    "# Original correlation matrix heatmap\n",
    "axes[1].imshow(original_corr_df, cmap='coolwarm', interpolation='nearest')\n",
    "axes[1].set_xticks(np.arange(len(original_corr_df)))\n",
    "axes[1].set_yticks(np.arange(len(original_corr_df)))\n",
    "axes[1].set_xticklabels(original_corr_df.columns, rotation=45)\n",
    "axes[1].set_yticklabels(original_corr_df.columns)\n",
    "axes[1].set_title(\"Original Correlation Matrix\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc842ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T21:41:54.931971Z",
     "start_time": "2023-07-19T21:41:54.923681Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to measure the distance between two correlation matrices using Frobenius norm\n",
    "def correlation_distance(matrix1, matrix2):\n",
    "    return np.linalg.norm(matrix1 - matrix2, ord='fro')\n",
    "\n",
    "\n",
    "current_distance = correlation_distance(matrix1=correlation_matrix_adjusted, matrix2=original_corr_df)\n",
    "current_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa9bd53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2233f174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1807a6b2",
   "metadata": {},
   "source": [
    "## Run the distribution fitter to check the distributions of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cfe1c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T21:01:45.766919Z",
     "start_time": "2023-07-19T21:01:45.727893Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Define the inputs and their probability distributions\n",
    "inputs = {\"input_1\": {\"mean\": 10, \"std_dev\": 2},\n",
    "          \"input_2\": {\"mean\": 20, \"std_dev\": 3}}\n",
    "\n",
    "# Number of iterations\n",
    "num_iterations = 10000\n",
    "\n",
    "# Storage for simulation results\n",
    "results = []\n",
    "\n",
    "# Run the simulation\n",
    "for i in range(num_iterations):\n",
    "    # Generate random values for each input based on its distribution\n",
    "    input_1 = np.random.normal(inputs[\"input_1\"][\"mean\"], inputs[\"input_1\"][\"std_dev\"])\n",
    "    input_2 = np.random.normal(inputs[\"input_2\"][\"mean\"], inputs[\"input_2\"][\"std_dev\"])\n",
    "\n",
    "    # Calculate the output of the model\n",
    "    output = input_1**2 +input_1*input_2+ input_2**2\n",
    "\n",
    "    # Store the result\n",
    "    results.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039421c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T21:02:47.253618Z",
     "start_time": "2023-07-19T21:02:46.931632Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Analyze the results\n",
    "mean_result = np.mean(results)\n",
    "std_dev_result = np.std(results)\n",
    "\n",
    "# Visualize the results\n",
    "sns.set_style('white')\n",
    "sns.set_context(\"paper\", font_scale = 2)\n",
    "\n",
    "sns.displot(data=results, x=results, kind=\"hist\", bins = 100, aspect = 1.5)\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(\"Mean result: \", mean_result)\n",
    "print(\"Standard deviation of result: \", std_dev_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb670e97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T21:11:45.816703Z",
     "start_time": "2023-07-19T21:05:15.357021Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in df_test.columns:\n",
    "    \n",
    "    print(\"col: \", col)\n",
    "    vals = list(df_test[col])\n",
    "    \n",
    "    f = Fitter(vals, distributions=get_distributions(),timeout=120, bins=50)#,xmin=0.1, xmax=1 ) \n",
    "    #get_common_distributions() ##['gamma','lognorm',\"beta\",\"burr\",\"norm\"]\n",
    "    f.fit()\n",
    "\n",
    "    f.summary()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6fbed9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T21:12:23.715024Z",
     "start_time": "2023-07-19T21:12:23.159415Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1415c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T21:14:40.515439Z",
     "start_time": "2023-07-19T21:14:39.643477Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test[\"ind_risk\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b5cb50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adf47ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc3902c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9c930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_bounds = []\n",
    "\n",
    "# possible_values = {\n",
    "#     'age': [20, 86],\n",
    "#     'ind_risk': [0, 1],\n",
    "#     'income': [0, 150000],\n",
    "#     'pers_exp': [0, 6000],\n",
    "#     'house_exp': [0, 4000],\n",
    "#     'taxes': [0, 2500],\n",
    "#     'transp_telecom': [0, 2500],\n",
    "#     'hobby': [0, 3000],\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "# for v in possible_values.values():\n",
    "    \n",
    "#     feature_bounds.append(tuple(v))\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# from scipy.stats import norm\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# def generate_synthetic_data_with_bounds(correlation_matrix, num_samples, feature_bounds):\n",
    "#     num_features = correlation_matrix.shape[0]\n",
    "#     lower_bounds, upper_bounds = zip(*feature_bounds)\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "#     # Check if the correlation matrix is valid (symmetric and positive definite)\n",
    "#     if not np.allclose(correlation_matrix, correlation_matrix.T):\n",
    "#         raise ValueError(\"Correlation matrix must be symmetric.\")\n",
    "#     if not np.all(np.linalg.eigvals(correlation_matrix) > 0):\n",
    "#         raise ValueError(\"Correlation matrix must be positive definite.\")\n",
    "    \n",
    "#     # Generate synthetic data using multivariate normal distribution\n",
    "#     mean = np.zeros(num_features)\n",
    "#     synthetic_data = np.random.multivariate_normal(mean, correlation_matrix, num_samples)\n",
    "    \n",
    "#     # Apply Gaussian copula to maintain correlation structure\n",
    "#     synthetic_data = norm.cdf(synthetic_data)\n",
    "    \n",
    "#     # Scale the data to the specified bounds for each feature\n",
    "#     for i in range(num_features):\n",
    "#         synthetic_data[:, i] = lower_bounds[i] + synthetic_data[:, i] * (upper_bounds[i] - lower_bounds[i])\n",
    "    \n",
    "#     return synthetic_data\n",
    "\n",
    "# # Example usage:\n",
    "# correlation_matrix = np.array(l_corr_matrix)\n",
    "\n",
    "# num_samples = 250000\n",
    "\n",
    "# synthetic_data = generate_synthetic_data_with_bounds(correlation_matrix, num_samples, feature_bounds)\n",
    "# print(synthetic_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0455053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_bounds = []\n",
    "\n",
    "# possible_values = {\n",
    "#     'age': [20, 86],\n",
    "#     'ind_risk': [0, 1],\n",
    "#     'income': [0, 150000],\n",
    "#     'pers_exp': [0, 6000],\n",
    "#     'house_exp': [0, 4000],\n",
    "#     'taxes': [0, 2500],\n",
    "#     'transp_telecom': [0, 2500],\n",
    "#     'hobby': [0, 3000],\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "# for v in possible_values.values():\n",
    "    \n",
    "#     feature_bounds.append(tuple(v))\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# from scipy.stats import norm\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# def generate_synthetic_data_with_bounds(correlation_matrix, num_samples, feature_bounds):\n",
    "#     num_features = correlation_matrix.shape[0]\n",
    "#     lower_bounds, upper_bounds = zip(*feature_bounds)\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "#     # Check if the correlation matrix is valid (symmetric and positive definite)\n",
    "#     if not np.allclose(correlation_matrix, correlation_matrix.T):\n",
    "#         raise ValueError(\"Correlation matrix must be symmetric.\")\n",
    "#     if not np.all(np.linalg.eigvals(correlation_matrix) > 0):\n",
    "#         raise ValueError(\"Correlation matrix must be positive definite.\")\n",
    "    \n",
    "#     # Generate synthetic data using multivariate normal distribution\n",
    "#     mean = np.zeros(num_features)\n",
    "#     synthetic_data = np.random.multivariate_normal(mean, correlation_matrix, num_samples)\n",
    "    \n",
    "#     # Apply Gaussian copula to maintain correlation structure\n",
    "#     synthetic_data = norm.cdf(synthetic_data)\n",
    "    \n",
    "#     # Scale the data to the specified bounds for each feature\n",
    "#     for i in range(num_features):\n",
    "#         synthetic_data[:, i] = lower_bounds[i] + synthetic_data[:, i] * (upper_bounds[i] - lower_bounds[i])\n",
    "    \n",
    "#     return synthetic_data\n",
    "\n",
    "# # Example usage:\n",
    "# correlation_matrix = np.array(l_corr_matrix)\n",
    "\n",
    "# num_samples = 250000\n",
    "\n",
    "# synthetic_data = generate_synthetic_data_with_bounds(correlation_matrix, num_samples, feature_bounds)\n",
    "# print(synthetic_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37ede76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912728f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55219470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7991208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3ea185",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T20:15:13.948425Z",
     "start_time": "2023-07-19T20:15:13.934869Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d5cb51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eba476d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d42ec764",
   "metadata": {},
   "source": [
    "# Old tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbad1b7b",
   "metadata": {},
   "source": [
    "## Apply business rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ff83e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c49ec8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T08:19:10.973368Z",
     "start_time": "2023-07-19T08:19:10.920827Z"
    }
   },
   "outputs": [],
   "source": [
    "# test = f\"[(df_merged['marit_stat'] =='Married') & (df_merged['house_memb'] >'2')]\"\n",
    "test = f\"[(df_merged['age'] <25) & (df_merged['lv_educ'] !='Higher')]\"\n",
    "\n",
    "list_mask = eval(test)\n",
    "df_merged[list_mask[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fa4990",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T07:58:14.381436Z",
     "start_time": "2023-07-19T07:58:14.366410Z"
    }
   },
   "outputs": [],
   "source": [
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de6038b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T08:00:05.427843Z",
     "start_time": "2023-07-19T08:00:05.353816Z"
    }
   },
   "outputs": [],
   "source": [
    "df_merged.loc[(df_merged['marit_stat'] =='Married') & (df_merged['house_memb'] >'2')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8018bbe",
   "metadata": {},
   "source": [
    "## Kolmogorov-Smirnov categorical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4528591",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T19:15:26.616919Z",
     "start_time": "2023-07-19T19:15:26.601908Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "old = {'sex': {'labels': ['M', 'F'], 'values': [0.4854368932, 0.5145631068]}}\n",
    "new = {'sex': {'labels': ['M', 'F'], 'values': [0.476, 0.524]}}\n",
    "\n",
    "# Extract the values for each category in the old and new distributions\n",
    "old_values = old['sex']['values']\n",
    "new_values = new['sex']['values']\n",
    "\n",
    "# Perform the KS test\n",
    "ks_statistic, p_value = ks_2samp(old_values, new_values)\n",
    "\n",
    "# Define the significance level (alpha) to test against the p-value\n",
    "alpha = 0.05\n",
    "\n",
    "# Check if the p-value is less than the significance level\n",
    "if p_value < alpha:\n",
    "    print(\"The new distribution is significantly different from the old distribution.\")\n",
    "else:\n",
    "    print(\"The new distribution is not significantly different from the old distribution.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadeff48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T18:51:42.862646Z",
     "start_time": "2023-07-19T18:51:42.835796Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(12345678)\n",
    "x = np.random.normal(0, 1, 1000)\n",
    "y = np.random.normal(0, 1, 1000)\n",
    "z = np.random.normal(1.1, 0.9, 1000)\n",
    "\n",
    "b = np.array([1,2,3,4,5])\n",
    "c = np.array([1,2,3,4,5])\n",
    "d = np.array([50, 100, 200, 400, 800])\n",
    "\n",
    "a = 0.05\n",
    "\n",
    "res = ks_2samp(x, y)\n",
    "res2 = ks_2samp(b,c)\n",
    "res3 = ks_2samp(b,d)\n",
    "print(\"x,y ks: \", ks_2samp(x, y))\n",
    "# Ks_2sampResult(statistic=0.022999999999999909, pvalue=0.95189016804849647)\n",
    "print(\"x,z ks: \", ks_2samp(x, z))\n",
    "print(\"b,c ks: \", ks_2samp(b, c))\n",
    "print(\"b,d ks: \", ks_2samp(b, d))\n",
    "\n",
    "\n",
    "# Ks_2sampResult(statistic=0.41800000000000004, pvalue=3.7081494119242173e-77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43884f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T18:51:44.022290Z",
     "start_time": "2023-07-19T18:51:44.008159Z"
    }
   },
   "outputs": [],
   "source": [
    "res3.pvalue <= a\n",
    "# False means Statistically insignificant - or the two distributions are considered the same!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd27a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14e2e86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ss2022]",
   "language": "python",
   "name": "conda-env-.conda-ss2022-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "360.433px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "412.85px",
    "left": "1124.77px",
    "right": "20px",
    "top": "113px",
    "width": "530.467px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
